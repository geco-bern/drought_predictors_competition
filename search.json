[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Drought Predictors Competition",
    "section": "",
    "text": "1 Introduction\nTODO: This book serves as an example of a machine learning (ML) based workflow to use earth observation predictors to quantify vegetation stress.\nTODO: it is an exercise in the framework for AGDS2 (link)\nTODO: vegetation stress (expressed as fLUE on eddy-covariance sites).\nTODO …\nThis book requires prior knowledge of programming in R, git and cloud based collaborative tools such as Github. The target group are students of the course Applied Geodata Science II (AGDS II) at the University of Bern, Switzerland. The necessary prior knowledge covered by the courses AGDS I and II. Many of these concepts are described in the accompanying, free online book AGDS.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#formal-course-work",
    "href": "index.html#formal-course-work",
    "title": "Drought Predictors Competition",
    "section": "1.1 Formal course work",
    "text": "1.1 Formal course work\nTODO: RMD and HTML\nTODO: Pull request to geco-bern/agds2_course/\nWhen reading this book as formal course work the requested format for handing in the exercises as listed in Chapter 2 is a single R markdown file (see REF), including its rendered html file.\nI will grade on the implementation of the code, as well as its critical assessment, and or trouble shooting. If you were stuck, document how you got unstuck in these assignments. If you are still stuck, list what efforts you made to get unstuck (and what failed results they yielded and how this informed your further reasoning).\nDocument problem solving extensively in between code blocks. Mention (cite) resources you consulted, packages used, etc. You will have to find the original source if you consult external resources, ChatGPT (or similar large language model chat services) are not a valid reference in and on itself.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "drought_prediction.html",
    "href": "drought_prediction.html",
    "title": "1  Drought prediction",
    "section": "",
    "text": "1.1 Unsupervised machine learning\nIn previous sections I have explained how the timing in the development of vegetation canopy density (i.e. using the leaf area index, or LAI) can be detected, and how it varies depending on the geography of the region. I introduced how this ties to the exchange of carbon and water between the biosphere and the atmosphere (REF). A small, first principles, example was provided on how to write your own phenology detection algorithm (REF) and how to use such data to model phenology, based upon environmental drivers (REF). In this section I will cover Land-Use and Land-Cover classification and explain how all these concepts relate.\nWhen we plot a time series of the LAI of a deciduous forest you note the steady seasonal changes when switching between winter, with low LAI values, to summer with high LAI values. However, different vegetation (and Land-Use and Land-Cover) types have different temporal LAI profiles. For example, a glacier will have permanent snow and no seasonal LAI signal. We can therefore discriminate (visually) between non-vegetative locations and vegetation based upon the combined spectral and temporal profiles across locations (REF).\nWe can use this concept, of differential temporal and spectral responses to map where certain Land-Use and Land-Cover types are dominant. In the above example, I used LAI which is a derived index which uses raw spectral data and an underlying model. However, satellite platforms provide raw information in various spectral bands. One can say the data are multi-dimensional, having both a temporal, spatial and spectral component (see REF). These various bands, or locations in the spectral domain, provide key insights into the state of the land surface (throughout the year). For example the combination of information in the red and near-infrared bands (spectral domains) provides key information to calculate the Normalized Difference Vegetation Index (NDVI) (Huete et al. 2002) an indicator of plant health and density. Other band combinations and or models lead to other indices, e.g. the LAI data previously used, with varying properties tailored to specific ecological, geo-morphological or other purposes (Zeng et al. 2022). All this spectral-temporal data combined with machine learning (clustering) approaches allows us to map the land surface in great detail. In this section I will discuss both unsupervised and supervised machine learning approaches to Land-Use and Land-Cover (LULC) mapping.\nWorking of the concept as demonstrated in REF we can use the spectral and temporal information across the landscape to classify a Swiss alpine scene into locations which have little seasonality and those which have some. For example you can calculate the mean and standard deviation of a full year and see how much variability you see across a year. Regions with a low LAI signal with little variability are most likely not associated with vegetation (e.g. glaciers, see REF). Classification of data in different classes (or clustering) can be accomplished using various methods. Clustering can either be unsupervised, where clustering is only defined by the number of classes one wants to divide the (multi-dimensional) dataset into, with no reference data to compare the results to.\nIn this example I use an unsupervised machine learning approach, called k-means clustering, to divide the dataset into two or more classes. These classes are clustered in a way which minimizes within-cluster variances, i.e. it ensures that pixels will look similar to each other (given a target number of clusters k to divide the dataset into).\nHere, we can use the lai_2012 dataset we previously downloaded, but we’ll use the raster representation as a starting point (as most geospatial data will come in multi-layer raster formats).\nAs a first step (ironically) I will convert this raster object back into a dataframe, since this is the format expected by many machine learning packages. However, this time it will be a wide data frame, where every pixel location is a row and every column a value for a given date (see REF). Alternatively, I could have converted the original lai_2012 data frame from a long format into a wide format using tidyr::pivot_wider(). Every row, representing a year for a given location, is a feature (vector) which contains the information on which the k-means clustering algorithm will operate.\n# # convert a multi-layer raster image\n# # to wide dataframe\n# df &lt;- as.data.frame(r, cell = TRUE)\n# \n# # the content of a single feature (vector)\n# # limited to the first 5 values for brevity\n# print(df[1:3,1:5])\nWe can now use the kmeans() algorithm to classify the data into two distinct groups or centers (k = 2). Note that we drop the first column from our dataframe as this contains the pixel indices, which are needed later on.\n# # cluster the data into k classes\n# clusters &lt;- kmeans(\n#   df[,-1],     # -1 removes column 'cell'\n#   centers = 2  # setting k to 2\n# )\nFinally, we map the cell values back onto those of the original extent of the LAI data (to retain their respective geographic position).\n# # use the original raster layout as\n# # a template for the new map (only\n# # using a single layer)\n# kmeans_map &lt;- terra::rast(r, nlyr=1)\n# \n# # assign to each cell value (location) of this\n# # new map using the previously exported cell\n# # values (NA values are omitted so a 1:1\n# # mapping would not work)\n# kmeans_map[df$cell] &lt;- clusters$cluster\n# #| code-fold: true\n# #| label: fig-kmeans-map\n# #| fig-cap: \"k-means classification map for two clusters and one year (2012) of leaf area index (LAI) data.\"\n# #| fig-align: \"center\"\n# #| out-width: \"100%\"\n# \n# library(leaflet)\n# \n# # set te colour scale manually\n# palcol &lt;- colorFactor(\n#   c(\"#78d203\", \"#f9ffa4\"),\n#   domain = 1:2,\n#   na.color = \"transparent\"\n#   )\n# \n# # build the leaflet map\n# leaflet() |&gt; \n#   addProviderTiles(providers$Esri.WorldTopoMap, group = \"World Topo\") |&gt;\n#   addProviderTiles(providers$Esri.WorldImagery, group = \"World Imagery\") |&gt;\n#   addRasterImage(\n#     kmeans_map,\n#     colors = palcol,\n#     opacity = 0.5,\n#     method = \"ngb\",\n#     group = \"k-means cluster results\"\n#     ) |&gt;\n#   addLayersControl(\n#     baseGroups = c(\"World Topo\",\"World Imagery\"),\n#     position = \"topleft\",\n#     options = layersControlOptions(collapsed = FALSE),\n#     overlayGroups = c(\"k-means cluster results\")\n#     ) |&gt;\n#   addLegend(\n#     colors = palcol(1:2),\n#     values = c(1, 2),\n#     title = \"cluster\",\n#     labels = c(1, 2)\n#     )\nAs the example uses an unsupervised classification we do not know what land cover types are included in this map. The model that we generate is therefore purely data informed, and not validated against external known Land-Use and Land-Cover locations. However, a quick visual inspection shows that for a k of 2 the split between the clusters divides vegetation from glaciers, water bodies, and urban areas (REF). The (seasonal) differences in LAI were used in the k-means analysis to minimize the (seasonal) variance between pixels. In particular, our analysis with two classes separates areas with a seasonal dynamic from those without one. Although the k-means algorithm is fast it only has one parameter which can shape the outcome of algorithm (i.e. k). The model is therefore too inflexible for more complex classification tasks. Moreover, the k-means model is rarely used as a scalable solution to generate maps based upon in-situ reference labels. Approaches using reference labels are part of supervised machine learning (see example below).\nIn the above example I used a single index, i.e. LAI, which does not provide sufficient information to distinguish between more subtle Land-Use or Land-Cover classes (e.g. evergreen forests and or mixed forest types). In short, a better approach would use more data and a more sophisticated model approach to create an informed model which scales easily to different land cover types and new locations.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Drought prediction</span>"
    ]
  },
  {
    "objectID": "drought_prediction.html#unsupervised-machine-learning",
    "href": "drought_prediction.html#unsupervised-machine-learning",
    "title": "1  Drought prediction",
    "section": "",
    "text": "For BookFor Exercises\n\n\n\n# # conversion from tidy data to a raster format\n# # as it is common to use raster data\n# r &lt;- MODISTools::mt_to_terra(\n#   lai_2012,\n#   reproject = TRUE\n#   )\n\n\n\n\n# # load buffered data\n# # that is stored in the data folder of the repo\n# r &lt;- terra::rast(here::here(\"../data/LAI.tiff\"))",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Drought prediction</span>"
    ]
  },
  {
    "objectID": "drought_prediction.html#supervised-machine-learning",
    "href": "drought_prediction.html#supervised-machine-learning",
    "title": "1  Drought prediction",
    "section": "1.2 Supervised machine learning",
    "text": "1.2 Supervised machine learning\nIn contrast to k-means, one can use supervised classification of data where reference data is used as labels on which to train a machine learning algorithm. A supervised machine learning algorithm will try to minimize the classification error on a known training or testing dataset. The methodology, model complexity and parameters are dependent on the provided data, the complexity of the problem and the available computational resources.\nFor example the creation of the MODIS land-cover and land-use product (MCD12Q2) uses &gt;1500 reference locations, three years of temporal data and a variety of multiple spectral bands, as well as ancillary data (topography, view angle geometry) to train their boosted classification tree (Friedl et al. 2002, 2010). In the below example I will try to recreate a part of the MCD12Q2 LULC workflow (red boxes, REF). A full introduction to machine learning is beyond the scope of this course and I refer to Boehmke and Greenwell (2020), Kuhn and Silge (2022) and the AGDS book for an introduction in machine learning using R.\n\n# #| label: fig-classification-workflow\n# #| fig-cap: \"The full MODIS MCD12Q1 LULC classification workflow (after Friedl et al. 2010). The red boxes highlights the section covered in the worked example.\"\n# #| fig-align: \"center\"\n# #| out-width: \"50%\"\n# #| echo: FALSE\n# knitr::include_graphics(\"./images/Friedl_2010.svg\")\n\n\n1.2.1 Ground truth reference data\nCritical in our exercise is the reference data we use to classify different Land-Use and Land-Cover types with. Generally ground truth data is used in order to create training and testing datasets. This ground truth data are locations which are visually validated to belong to a particular Land-Use or Land-Cover class. These data are gathered by in-situ surveys, or leverage high(er) resolution data and visual interpretation to confirm the the Land-Use or Land-Cover type.\nFor example, the LUCAS database of the European Commission Joint Research Center provides three-yearly survey data on the Land-Use and Land-Cover state (d’Andrimont et al. 2020), while the Geo-Wiki project used crowdsourcing to confirm Land-Use and Land-Cover types using high resolution remote sensing imagery (Fritz et al. 2017). Other products use in house databases using similar approaches (Friedl et al. 2010). In this example, I will rely on the freely available crowdsourced (Geo-Wiki) dataset (Fritz et al. 2017). These ground truth labels differ slightly from the International Geosphere-Biosphere Programme (IGBP) classes used in the MCD12Q1 product. Nevertheless, the general principles are the same.\n\n# # Read the reference (validation) sites from\n# # Fritz et al. 2017 straight from Zenodo.org\n# validation_sites &lt;- readr::read_csv(\n#   \"https://zenodo.org/record/6572482/files/Global%20LULC%20reference%20data%20.csv?download=1\"\n# )\n\nI will restrict the number of reference validation sites to a manageable number of 150 random locations for each Land-Use or Land-Cover class, limited to high quality locations on the northern hemisphere (as we will apply our analysis regionally to Switzerland). The ground truth data in Fritz et al. (2017) contains data from different crowdsourcing competitions. Nr. 1 refers to Land-Use and nr. 4 to Land-Cover classes. The below routine shows how to gather 150 random locations for each Land-Use or Land-Cover class from Fritz et al. (2017). The locations of this data will be used to train and test the supervised machine learning algorithm.\n\nFor BookFor Exercises\n\n\n\n# # filter out data by competition,\n# # coverage percentage and latitude\n# # (use round brackets to enclose complex\n# # logical statements in a filter call!)\n# validation_selection &lt;- validation_sites |&gt;\n#     dplyr::filter(\n#       (competition == 4 | competition == 1),\n#       perc1 &gt; 80,\n#       lat &gt; 0\n#     )\n# \n# # the above selection includes all data\n# # but we now subsample to 150 random locations\n# # per (group_by()) land cover class (LC1)\n# # set a seed for reproducibilty\n# set.seed(0)\n# \n# validation_selection &lt;- validation_selection |&gt;\n#     dplyr::slice_sample(n = 150, by = LC1)\n# \n# # split reference selection\n# # by land cover type into a nested\n# # list, for easier processing\n# # later on\n# validation_selection &lt;- validation_selection |&gt;\n#     dplyr::group_by(LC1) |&gt;\n#     dplyr::group_split()\n\n\n\n\n# validation_selection &lt;- readr::read_rds(\n#   here::here(\"data/competition_selection.rds\")\n# );\n# # train and test data for the competition was\n# # downloaded with `data-raw/download_competition_data.R`\n# # and prepared with `data-raw/compile_training_data.R`\n# # (see https://github.com/geco-bern/handfull_of_pixels/)\n# # and deposited on Zenodo.\n# \n# # see further below how to directly load train and \n# # test data (containing predictors and land-cover labels) \n# # from Zenodo. (Since this data is already prepared \n# # it is much quicker than the download with AppEEARS.)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe samples are generated randomly, although a random seed ensures some reproducibility it is wise to save your site selection on file.\n\n\n\n\n1.2.2 Multi-spectral training data\nAs with our k-means clustering example we need predictor data to inform our supervised classification. The MODIS data product MCD43A4 provides daily multi-spectral data, which is corrected for (geometric) view angle effects between the satellite and the sun. In below example in the interest of time, we gather data for only four spectral bands (1 to 4) from the MCD43A4 data product. This is a subset of what is used in the formal MCD12Q1 LULC product.\nThe required MCD43A4 data is not readily available using the {MODISTools} R package, as previously introduced, and I will therefore rely on the {appears} R package (Hufkens 2023) to query and download training data. The {appears} package relies on the NASA AppEEARS API service which provides easy access to remote sensing data subsets similar to the ORNL DAAC service, as used by {MODISTools}. The provided data covers more data products, but does require a login (API key) limiting ad-hoc accessibility.\n\n\n\n\n\n\nWarning\n\n\n\nI refer to the {appears} documentation for the setup and use of an API key. The instructions below assume you have registered and have a working key installed in your R session.\n\n\n\nFor BookFor Exercises\n\n\n\n# # for every row download the data for this\n# # location and the specified reflectance\n# # bands\n# task_nbar &lt;- lapply(validation_selection, function(x){\n#   \n#   # loop over all list items (i.e. land cover classes)\n#   base_query &lt;- x |&gt;\n#     dplyr::rowwise() |&gt;\n#     do({\n#       data.frame(\n#         task = paste0(\"nbar_lc_\",.$LC1),\n#         subtask = as.character(.$pixelID),\n#         latitude = .$lat,\n#         longitude = .$lon,\n#         start = \"2012-01-01\",\n#         end = \"2012-12-31\",\n#         product = \"MCD43A4.061\",\n#         layer = paste0(\"Nadir_Reflectance_Band\", 1:4)\n#       )\n#     }) |&gt;\n#     dplyr::ungroup()\n#   \n#   # build a task JSON string \n#   task &lt;- rs_build_task(\n#     df = base_query\n#   )\n#   \n#   # return task\n#   return(task)\n# })\n# \n# # Query the appeears API and process\n# # data in batches - this function\n# # requires an active API session/login\n# rs_request_batch(\n#   request = task_nbar,\n#   workers = 10,\n#   user = \"your_api_id\",\n#   path = tempdir(),\n#   verbose = TRUE,\n#   time_out = 28800\n# )\n\n\n\n\n# train and test data for the competition was\n# downloaded with `data-raw/download_competition_data.R`\n# and prepared with `data-raw/compile_training_data.R`\n# (see https://github.com/geco-bern/handfull_of_pixels/)\n# and deposited on Zenodo.\n\n# see further below how to directly load train and \n# test data (containing predictors and land-cover labels) \n# from Zenodo. (Since this data is already prepared \n# it is much quicker than the download with AppEEARS.)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAppEEARS downloads might take a while! In the code above the default directory is also set to the temporary directory. To use the above code make sure to change the download path to a more permanent one.\n\n\nWith both training and reference data downloaded we can now train a supervised machine learning model! We do have to wrangle the data into a format that is acceptable for machine learning tools. In particular, we need to convert the data from a long format to a wide format (see REF), where every row is a feature vector. The {vroom} package is used to efficiently read in a large amount of similar CSV files into a large dataframe using a single list of files (alternatively you can loop over and append files using base R).\n\nFor BookFor Exercises\n\n\n\n# # list all MCD43A4 files, note that\n# # that list.files() uses regular\n# # expressions. Thus when using wildcards\n# # such as *, you can use glob2rx() to \n# # convert these wildcards to regular \n# # expressions\n# files &lt;- list.files(\n#   tempdir(),\n#   glob2rx(\"*MCD43A4-061-results*\"),\n#   recursive = TRUE,\n#   full.names = TRUE\n# )\n# \n# # read in the data (very fast)\n# # with {vroom} and set all\n# # fill values (&gt;=32767) to NA\n# nbar &lt;- vroom::vroom(files)\n# nbar[nbar &gt;= 32767] &lt;- NA\n# \n# # retain the required data only\n# # and convert to a wide format\n# nbar_wide &lt;- nbar |&gt;\n#   dplyr::select(\n#     Category,\n#     ID,\n#     Date,\n#     Latitude,\n#     Longitude,\n#     starts_with(\"MCD43A4_061_Nadir\")\n#   ) |&gt;\n#   tidyr::pivot_wider(\n#     values_from = starts_with(\"MCD43A4_061_Nadir\"),\n#     names_from = Date\n#   )\n# \n# # split out only the site name,\n# # and land cover class from the\n# # selection of validation sites\n# # (this is a nested list so we\n# # bind_rows across the list)\n# sites &lt;- validation_selection |&gt;\n#   dplyr::bind_rows() |&gt;\n#   dplyr::select(\n#     pixelID,\n#     LC1\n#   ) |&gt;\n#   dplyr::rename(\n#     Category = \"pixelID\"\n#   )\n# \n# # combine the NBAR and land-use\n# # land-cover labels by location\n# # id (Category)\n# ml_df &lt;- left_join(nbar_wide, sites) |&gt;\n#     dplyr::select(\n#     LC1,\n#     contains(\"band\")\n#   )\n\n\n\n\n# train and test data for the competition was\n# downloaded with `data-raw/download_competition_data.R`\n# and prepared with `data-raw/compile_training_data.R`\n# (see https://github.com/geco-bern/handfull_of_pixels/)\n# and deposited on Zenodo.\n\n# see further below how to directly load train and \n# test data (containing predictors and land-cover labels) \n# from Zenodo. (Since this data is already prepared \n# it is much quicker than the download with AppEEARS.)\n\n\n\n\n\n\n1.2.3 Model training\nThis example will try to follow the original MODIS MCD12Q1 workflow closely which calls for a boosted regression classification approach (Friedl et al. 2010). This method allows for the use of a combination of weak learners to be combined into a single robust ensemble classification models. The in depth discussion of the algorithm is beyond the scope of this course and I refer to specialized literature for more details. To properly evaluate or model we need to split our data in a true training dataset, and a test dataset. The test dataset will be used in the final model evaluation, where samples are independent of those contained within the training dataset (Boehmke and Greenwell 2020).\n\nFor BookFor Exercises\n\n\n\n# # select packages\n# # avoiding tidy catch alls\n# library(rsample)\n# \n# # create a data split across\n# # land cover classes\n# ml_df_split &lt;- ml_df |&gt;\n#   rsample::initial_split(\n#   strata = LC1,\n#   prop = 0.8\n# )\n# \n# # select training and testing\n# # data based on this split\n# train &lt;- rsample::training(ml_df_split)\n# test &lt;- rsample::testing(ml_df_split)\n\n\n\n\n# # train and test data for the competition was\n# # downloaded with `data-raw/download_competition_data.R`\n# # and prepared with `data-raw/compile_training_data.R`\n# # (see https://github.com/geco-bern/handfull_of_pixels/)\n# # and deposited on Zenodo.\n# \n# \n# # see here how to directly load train and test data from Zenodo\n# download.file(\n#   url = \"https://zenodo.org/records/8298491/files/test_data.rds?download=1\",     \n#   destfile = file.path(tempdir(), \"test_data.rds\"))\n# download.file(\n#   url = \"https://zenodo.org/records/8298491/files/training_data.rds?download=1\", \n#   destfile = file.path(tempdir(), \"training_data.rds\"))\n# \n# test_data_Zenodo     &lt;- readr::read_rds(\n#   file.path(tempdir(), \"test_data.rds\"))\n# training_data_Zenodo &lt;- readr::read_rds(\n#   file.path(tempdir(), \"training_data.rds\"))\n# \n# # ensure training and test data contain same predictor/feature variables\n# setdiff(names(training_data_Zenodo), \n#         names(test_data_Zenodo)) # pixelID, LC1, lat, lon\n# setdiff(names(test_data_Zenodo),     \n#         names(training_data_Zenodo))\n# \n# train &lt;- training_data_Zenodo |&gt; \n#   select(-c(pixelID, lat, lon)) # remove ID, lat, lon\n# test  &lt;- test_data_Zenodo                                           \n# # NOTE: for the competition, column 'LC1' was removed from the \n# #       test data\n\n\n\n\nWith both a true training and testing dataset in place we can start to implement our supervised machine learning model. I will use a “tidy” machine learning modelling approach. Similar to the data management practices described in REF, a tidy modelling approach relies mostly on sentence like commands using a pipe (|&gt;) and workflows (recipes). This makes formulating models and their evaluation more intuitive for many. For an in depth discussion on tidy modelling in R I refer to Kuhn and Silge (2022). Now, let’s get started.\n\nModel structure and workflow\nTo specify our model I will use the {parsnip} R package which goal it is “… to provide a tidy, unified interface to models that can be used to try a range of models without getting bogged down in the syntactical minutiae of the underlying packages”. Parsnip therefore will remove some of the complexity of using a package such as {xgboost} might present. It also allows you to switch between different model structures with ease, only swapping a few arguments. Parsnip will make sure that model parameters are correctly populated and forwarded.\nFollowing (Friedl et al. 2010) we will implement a boosted regression (classification) tree using the {xgboost} R package, via the convenient {parsnip} R package interface. The model allows for a number of hyper-parameters, i.e. parameters which do not define the base {xgboost} algorithm but the implementation and structure of it. In this example hyper-parameters for the number of trees is fixed at 50, while the tree depth is flexible (parameters marked tune(), see below).\n\n\n\n\n\n\nNote\n\n\n\nThere are many more hyper-parameters. For brevity and speed these are kept at a minimum. However, model performance might increase when tuning hyper-parameters more extensively.\n\n\n\n# # load the parsnip package\n# # for tidy machine learning\n# # modelling and workflows\n# # to manage workflows\n# library(parsnip)\n# library(workflows)\n# \n# # specify our model structure\n# # the model to be used and the\n# # type of task we want to evaluate\n# model_settings &lt;- parsnip::boost_tree(\n#   trees = 50,\n#   min_n = tune(),\n#   tree_depth = tune(),\n#   # learn_rate = tune()\n#   ) |&gt;\n#   set_engine(\"xgboost\") |&gt;\n#   set_mode(\"classification\")\n# \n# # create a workflow compatible with\n# # the {tune} package which combines\n# # model settings with the desired\n# # model structure (data / formula)\n# xgb_workflow &lt;- workflows::workflow() |&gt;\n#   add_formula(as.factor(LC1) ~ .) |&gt;\n#   add_model(model_settings)\n# \n# print(xgb_workflow)\n\n\n\nHyperparameter settings\nTo optimize our model we need to configure (tune) the hyper-parameters which were left variable in the model settings. How we select these hyper-parameters is determined by sampling a parameter space, defined in our example by latin hypercube sampling. The {dials} R package provides a “tidymodels” compatible functions to support building latin hypercubes for our parameter search. In this example, I use the extract_param_set_dials() function to automatically populate the latin hypercube sampling settings. However, these can be specified manually when needed.\n\n# # load the dials package\n# # responsible for (hyper) parameter\n# # sampling schemes to tune\n# # parameters (as extracted)\n# # from the model specifications\n# library(tune)\n# library(dials)\n# \n# hp_settings &lt;- dials::grid_latin_hypercube(\n#   tune::extract_parameter_set_dials(xgb_workflow),\n#   size = 3\n# )\n# \n# print(hp_settings)\n\n\n\nParameter estimation and cross-validation\nWe can move on to the actual model calibration. To ensure robustness of our model (hyper-) parameters across the training dataset the code below also implements a cross-validation to rotate through our training data using different subsets. The below code tunes the model parameters across the cross-validation folds and returns all these results in one variable, xgb_results.\n\n# # set the folds (division into different)\n# # cross-validation training datasets\n# folds &lt;- rsample::vfold_cv(train, v = 3)\n# \n# # optimize the model (hyper) parameters\n# # using the:\n# # 1. workflow (i.e. model)\n# # 2. the cross-validation across training data\n# # 3. the (hyper) parameter specifications\n# # all data are saved for evaluation\n# xgb_results &lt;- tune::tune_grid(\n#   xgb_workflow,\n#   resamples = folds,\n#   grid = hp_settings,\n#   control = tune::control_grid(save_pred = TRUE)\n# )\n\nWhen the model is tuned across folds the results show varied model performance. In order to select the best model, according to a set metric, you can use the select_best() function (for a specific metric). This will extract the model hyperparameters for model training.\n\n# # select the best model based upon\n# # the root mean squared error\n# xgb_best &lt;- tune::select_best(\n#   xgb_results,\n#   metric = \"roc_auc\"\n#   )\n# \n# # cook up a model using finalize_workflow\n# # which takes workflow (model) specifications\n# # and combines it with optimal model\n# # parameters into a model workflow\n# xgb_best_hp &lt;- tune::finalize_workflow(\n#   xgb_workflow,\n#   xgb_best\n# )\n# \n# print(xgb_best_hp)\n\nHowever, the returned object does not specify the model structure. To combine both the model structure (workflow) with the optimal parameters we need to combine both. In short, we need to finalize_workflow() which combines the model workflow with the model parameters into a final functional model workflow with optimal hyper-parameters. Note that the resulting model workflow does not contain any tunable (tune()) fields as shown above! The selected model workflow, given our provided constrains on the hyperparamters, has 50 trees, has minimum 11 data points in a node (min_n) and a tree depth of 5. We will use this workflow to fit() a final training run (on all training data data, i.e. including parts of the data that were set apart for the cross-validation runs) with the chosen optimal hyper-parameters. This returns our final model which provides the desired (classification) results!\n\n# # train a final (best) model with optimal\n# # hyper-parameters\n# xgb_best_model &lt;- fit(xgb_best_hp, train)\n\n\n\n\n1.2.4 Model evaluation on test data\nIn machine learning model evaluation can be achieved in various ways and the standard exploration of the accuracy and variables of importance (and their relative contributions) to the model strength are beyond the scope of this example. I will only focus on the standard methodology and terminology as used in remote sensing and GIS fields.\n\nConfusion matrix and metrics\nIn the case of Land-Use and Land-Cover mapping classifications results are often reported as an confusion matrix and their associated metrics. The confusion matrix tells us something about accuracy (as perceived by users or producers), while the overall accuracy and Kappa coefficient allow us to compare the accuracy across modelled (map) results.\nIn Table 1.1 a three class confusion matrix is shown with the model prediction in rows and the reference (real) classes in columns. In addition, the user and producer accuracies are shown. The user accuracy is the fraction of correctly predicted classes with respect to the false positives (Type I) errors for a given prediction class. The producer accuracy is the fraction of correctly predicted classes with respect to the false negatives (Type II) errors for a given reference class.\n\n\n\nTable 1.1: Confusion matrix with classification results from top to bottom, reference results from left to right. Results show the labels (1-3) and their respective false positive and negative results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRef. 1\nRef. 2\nRef. 3\ntotal\nUser accuracy (Type I)\nKappa\n\n\n\n\nPred. 1\n49\n4\n4\n57\n0.89\n\n\n\nPred. 2\n2\n40\n2\n44\n0.90\n\n\n\nPred. 3\n3\n3\n59\n65\n0.90\n\n\n\ntotal\n54\n47\n65\n166\n\n\n\n\nProducer accuracy (Type II)\n0.90\n0.85\n0.90\n\n0.89\n\n\n\nKappa\n\n\n\n\n\n0.84\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn other words:\nUser accuracy: For example, among the sites that were predicted as class one (1) (first row) some were actually class two or three (2,3). The model committed the wrong label (1) to these sites. These false positives are therefore also called commission errors. Imagine a user of a prediction map is interested in a specific pixel that was predicted as class one (1), the user accuracy thus estimates how accurate this attribution to class one is.\nProducer accuracy: Similarly, imagine a producer of a prediction map. Unlike the user, the producer has access to the reference data and wonders e.g. for all reference points of class one (1) (first column), how many got predicted correctly. For example, for all sites identified as class 1 in the reference data, some were predicted as class 2 and 3 by the model. These sites were omitted from the correct class and are thus also called omission errors.\nIn short, in remote sensing, the Type I and II errors are rephrased as the perspective taken during the assessment, either the user or the producer. In a strict machine learning context the user and producer accuracy would be called precision and recall, respectively. I refer to Boehmke and Greenwell (2020), Kuhn and Silge (2022) and the AGDS book for an in depth discussion on machine learning model evaluation. Also these online answers ([1], [2]) additionally explain the kappa statistic.\n\n\nSimple confusion matrices can be calculated using R using the table() function comparing the true reference labels with the predicted values for our model. Using the function caret::confusionMatrix() gives directly additional overall- and by-class- statistics as shown below:\n\nFor BookFor Exercises\n\n\n\n# #| warning: false\n# # run the model on our test data\n# # using predict()\n# test_results &lt;- predict(xgb_best_model, test)\n# \n# # load the caret library to\n# # access confusionMatrix functionality\n# library(caret)\n# \n# # use caret's confusionMatrix function to get\n# # a full overview of metrics\n# caret::confusionMatrix(\n#   reference = as.factor(test$LC1),\n#   data = as.factor(test_results$.pred_class)\n#   )\n\n\n\n\n# # NOTE: for the competition column 'LC1' was removed from \n# #       the test data. Thus you can't compute the scores \n# #       yourself.\n# #       \n# #       Instead upload your predictions from your best \n# #       model as a pull request to\n# #       https://github.com/geco-bern/agds2_course.\n# #       \n# #       To do so: \n# #       a) save your results as .*csv: \n#            readr::write_csv(\n#               x    = dplyr::rename(test_results, \n#                                    lulc_class = .pred_class),\n#               file = \"~/Desktop/username_results.csv\")\n# #       a) fork the repository 'agds2_course', \n# #       b) add and commit your results as \n# #          'data/leaderboard/fall_2025/username_results.csv', \n# #       c) and open a pull request (PR) from your forked \n# #          repository to the main repository at \n# #          'geco-bern/agds2_course'.\n# #       \n# #       Your predictions will then be added to the the leader \n# #       board on the course website at \n# #       https://geco-bern.github.io/agds2_course/leaderboard_fall_2025.html\n\n\n\n\n\n\n\n1.2.5 Model scaling to raster data\nTo scale our new model to other locations, or regions we will below download additional data covering the region around Bern. The code below demonstrates how to download geospatial raster data with the {appeears} R package, rather than point data used during training. This data will then be used to run our previously trained model, and the results will be presented as a map. Since our workflow closely followed the first steps of the MODIS MCD12Q1 LULC map protocol we will compare our map to the final MODIS MCD12Q1 product. (Since we did not use exactly the same MODIS IGBP Land-Use and Land-Cover classes we need to perform some remapping before plotting.)\n\nData download\nTo scale our analysis spatially we need to download matching data, i.e. MODIS MCD43A4 NBAR data for bands 1 through 4, for a geographic regions. The {appeears} R package has an roi parameter which can take SpatRaster map data. Providing a SpatRaster map will match its extent to the AppEEARS query. I will use the map generated during our k-means clustering exercise as the input for building an API task. Alternatively, you can provide an extent yourself using a polygon, as specified using the {sf} R package (REF).\n\n# # We can define an appeears\n# # download task using a simple\n# # dataframe and a map from which\n# # an extent is extracted\n# task_df &lt;- data.frame(\n#   task = \"raster_download\",\n#   subtask = \"swiss\",\n#   start = \"2012-01-01\",\n#   end = \"2012-12-31\",\n#   product = \"MCD43A4.061\",\n#   layer = paste0(\"Nadir_Reflectance_Band\", 1:4)\n# )\n# \n# # build the area based request/task\n# # using the extent of our previous\n# # kmeans map, export all results\n# # as geotiff (rather than netcdf)\n# task &lt;- rs_build_task(\n#   df = task_df,\n#   roi = kmeans_map,\n#   format = \"geotiff\"\n# )\n# \n# # request the task to be executed\n# # with results stored in a\n# # temporary location (can be changed)\n# rs_request(\n#   request = task,\n#   user = \"your_api_id\",\n#   transfer = TRUE,\n#   path = tempdir(),\n#   verbose = TRUE\n# )\n\n\n\n\n\n\n\nNote\n\n\n\nAppEEARS downloads might take a while! In the code above the default directory is also set to the temporary directory. To use the above code make sure to change the download path to a more permanent one.\n\n\n\n\nModel prediction\nThe downloaded data (by default in tempdir()) are a collection of geotiff files of NBAR reflectance bands and their matching quality control data. In this demonstration I will not process the more nuanced quality control flags. Therefore, I only list the reflectance files, and read in this list of geotiffs into a stack by calling rast().\n\nfiles &lt;- list.files(\n  tempdir(),\n  \"*Reflectance*\",\n  recursive = TRUE,\n  full.names = TRUE\n)\n\n# load this spatial data to run the model\n# spatially\nswiss_multispec_data &lt;- terra::rast(files)\n\nThe model we created is specific when it comes to naming variables, i.e. the naming of the bands in our spatial data matters and has to match those of the model. Due to inconsistencies in the AppEEARS API one has to rename the band names ever so slightly.\n\n# # the model only works when variable names\n# # are consistent we therefore rename them\n# band_names &lt;- data.frame(\n#   name = names(swiss_multispec_data)\n# ) |&gt;\n#   mutate(\n#     date = as.Date(substr(name, 40, 46), format = \"%Y%j\"),\n#     name = paste(substr(name, 1, 35), date, sep = \"_\"),\n#     name = gsub(\"\\\\.\",\"_\", name)\n#   )\n# \n# # reassign the names of the terra image stack\n# names(swiss_multispec_data) &lt;- band_names$name\n\nWith all band names in line with the expected variables in our model we can now scale it by using terra::predict(). This function is the {terra} R package equivalent of the predict() function for general statistical models. This function allows you to call a compatible model for SpatRaster data, by running it along the time/band axis of the raster stack. I ask for the model probabilities to be returned, as this gives a more granular overview of the model results (see type argument, REF).\n\n# # return probabilities, where each class is\n# # associated with a layer in an image stack\n# # and the probabilities reflect the probabilities\n# # of the classification for said layer\n# lulc_probabilities &lt;- terra::predict(\n#   swiss_multispec_data,\n#   xgb_best_model,\n#   type = \"prob\"\n# )\n\n\n# #| code-fold: true\n# #| label: fig-classification-probs\n# #| fig-cap: \"Classification probabilities, as generated for all 10 Land-Use and Land-Cover (LULC) classes within our xgboost algorithm, for the year 2012 across a Swiss spatial subset.\"\n# #| fig-align: \"center\"\n# #| out-width: \"100%\"\n# \n# ggplot() +\n#   tidyterra::geom_spatraster(data = lulc_probabilities) +\n#   scale_fill_viridis_c(\n#     na.value = NA,\n#     name = \"Class probabilities\",\n#     option = \"magma\"\n#     ) +\n#   scale_x_continuous(breaks = seq(-180, 180, 2)) +\n#   theme_bw() +\n#   theme(\n#     legend.position = \"bottom\"\n#     ) +\n#   facet_wrap(~lyr)\n\nOne can create a formal Land-Use and Land-Cover map by reducing this dataset by returning the layer for which the probability is highest, using which.max. As seen in REF, you can apply a function to all layers across pixels using the terra::app() function. The returned data is a Land-Use and Land-Cover map with classes 1 to 10, as shown below (REF).\n\n# # generate the map by selecting maximum probabilities\n# # from the model output\n# lulc_map &lt;- terra::app(lulc_probabilities, which.max)\n\n\n# #| code-fold: true\n# #| label: fig-spatial-lulc\n# #| fig-cap: \"A supervised machine learning based Land-Use and Land-Cover (LULC) map, based upon four MODIS MCD43A4 bands (1-4) using a boosted regression tree classification (xgboost). LULC classes were defined by Fritz et al. 2017. For comparison MODIS MCD12Q1 LULC (IGBP) data was remapped to the LULC classes of Fritz et al. 2017.\"\n# #| fig-align: \"center\"\n# #| out-width: \"100%\"\n# \n# classes &lt;- c(\n#     \"Tree Cover\",\n#     \"Shrub Cover\",\n#     \"Herbaceous Vegetation & Grassland\",\n#     \"Cultivated and Managed\",\n#     \"Mosaic: Managed & Natural Vegetation\",\n#     \"Regularly Flooded & Wetland\",\n#     \"Urban & Built Up\",\n#     \"Snow and Ice\",\n#     \"Barren\",\n#     \"Open Water\"\n#   )\n# \n# # set te colour scale manually\n# palcol &lt;- colorFactor(\n#   c(\n#     \"#05450a\",\n#     \"#78d203\",\n#     \"#009900\",\n#     \"#c24f44\",\n#     \"#ff6d4c\",\n#     \"#27ff87\",\n#     \"#a5a5a5\",\n#     \"#69fff8\",\n#     \"#f9ffa4\",\n#     \"#1c0dff\"\n#     ),\n#   na.color = NA,\n#   domain = 1:10\n# )\n# \n# # build the leaflet map\n# leaflet() |&gt; \n#   addProviderTiles(providers$Esri.WorldTopoMap, group = \"World Topo\") |&gt;\n#   addProviderTiles(providers$Esri.WorldImagery, group = \"World Imagery\") |&gt;\n#   addRasterImage(\n#     lulc_map,\n#     colors = palcol,\n#     opacity = 0.8,\n#     method = \"ngb\",\n#     group = \"XGBOOST\"\n#   ) |&gt;\n#   addRasterImage(\n#     modis_lulc,\n#     colors = palcol,\n#     opacity = 0.8,\n#     method = \"ngb\",\n#     group = \"MODIS MCD12Q1\"\n#   ) |&gt;\n#   addLayersControl(\n#     baseGroups = c(\"World Topo\", \"World Imagery\"),\n#     position = \"topleft\",\n#     options = layersControlOptions(collapsed = FALSE),\n#     overlayGroups = c(\"XGBOOST\", \"MODIS MCD12Q1\")\n#   ) |&gt;\n#   hideGroup(\"MODIS MCD12Q1\") |&gt;\n#   addLegend(\n#     colors = palcol(1:10),\n#     values = 1:10,\n#     labels = classes,\n#     title = \"Land-Use and Land-Cover class\"\n#   )\n\n\n\n\n\nBoehmke, Brad, and Brandon M Greenwell. 2020. Hands-On Machine Learning with R. Boca Raton, US: CRC Press. https://www.routledge.com/Hands-On-Machine-Learning-with-R/Boehmke-Greenwell/p/book/9781138495685.\n\n\nd’Andrimont, Raphaël, Momchil Yordanov, Laura Martinez-Sanchez, Beatrice Eiselt, Alessandra Palmieri, Paolo Dominici, Javier Gallego, et al. 2020. “Harmonised LUCAS in-Situ Land Cover and Use Database for Field Surveys from 2006 to 2018 in the European Union.” Scientific Data 7 (1): 352. https://doi.org/10.1038/s41597-020-00675-z.\n\n\nFriedl, M A, D K McIver, J C F Hodges, X Y Zhang, D Muchoney, A H Strahler, C E Woodcock, et al. 2002. “Global Land Cover Mapping from MODIS: Algorithms and Early Results.” Remote Sensing of Environment 83 (1-2): 287–302. http://www.sciencedirect.com/science/article/B6V6V-46RDDFS-2/2/498151a48b317e5bb23b15033a694d4e.\n\n\nFriedl, M A, D Sulla-Menashe, B Tan, A Schneider, N Ramankutty, A Sibley, and X M Huang. 2010. “MODIS Collection 5 Global Land Cover: Algorithm Refinements and Characterization of New Datasets.” Remote Sensing of Environment 114 (1): 168–82. https://doi.org/10.1016/j.rse.2009.08.016.\n\n\nFritz, Steffen, Linda See, Christoph Perger, Ian McCallum, Christian Schill, Dmitry Schepaschenko, Martina Duerauer, et al. 2017. “A Global Dataset of Crowdsourced Land Cover and Land Use Reference Data.” Scientific Data 4 (1): 170075. https://doi.org/10.1038/sdata.2017.75.\n\n\nHuete, A, K Didan, T Miura, E P Rodriguez, X Gao, and L G Ferreira. 2002. “Overview of the Radiometric and Biophysical Performance of the MODIS Vegetation Indices.” Remote Sensing of Environment 83 (1-2): 195–213. citeulike-article-id:274524http://dx.doi.org/10.1016/S0034-4257(02)00096-2.\n\n\nHufkens, Koen. 2023. “Bluegreen-Labs/Appeears: Appeears: An Interface to the NASA AppEEARS API.” Zenodo. https://doi.org/10.5281/zenodo.7958270.\n\n\nKuhn, Max, and Julia Silge. 2022. Tidy Modeling with R: A Framework for Modeling in the Tidyverse. 1st edition. Beijing Boston Farnham Sebastopol Tokyo: O’Reilly Media.\n\n\nZeng, Yelu, Dalei Hao, Alfredo Huete, Benjamin Dechant, Joe Berry, Jing M. Chen, Joanna Joiner, et al. 2022. “Optical Vegetation Indices for Monitoring Terrestrial Ecosystems Globally.” Nature Reviews Earth & Environment 3 (7): 477–93. https://doi.org/10.1038/s43017-022-00298-5.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Drought prediction</span>"
    ]
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "2  Exercise",
    "section": "",
    "text": "2.1 Phenology trends and algorithms\nThese exercises cover all materials up to REF. A proper understanding of these chapters is required to complete these exercises. Exercises are at times formulated in long form, not simple bullet points, in order to partially mimic formal descriptions as you would find in a methods section of an academic journal, or a reference manual.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "exercises.html#phenology-trends-and-algorithms",
    "href": "exercises.html#phenology-trends-and-algorithms",
    "title": "2  Exercise",
    "section": "",
    "text": "2.1.1 Physical geography and phenology\nInterpret the results of REF and the fit model as shown in the collapsed note at the end of the section.\n\nWhat does the intercept indicate?\nHow can you interpret the slope?\nHow to convert the established relationship with altitude, to one with temperature\n\nWithout actually doing it, just describe how you would go about this and what you would expect? Can you approximate the effect of 1 degree of warming?\n\n\n\n\n2.1.2 Temporal and spatial anomalies\nFor a location near the Adirondacks in the North-Eastern United States (Figure 2.1) gather phenology data on both the day of greenup and the day of maximum canopy development of a location centered on 43.5\\(^\\circ\\)N and 74.5\\(^\\circ\\)W. Use a product that directly provides these quantities. Gather data for all pixels 100 km around this location for years 2001 to 2010. Ensure you have the right region, e.g. by plotting it terra::plot(your_raster). Similarly, download land cover data for the year 2010 for the same spatial extent, and only consider IGBP broadleaf and mixed forest classes in your analysis.\nFor the years 2001 - 2009 calculate the long term mean (LTM) and standard deviation (SD) of the phenology metrics. Calculate location with an early greenup for 2010 (&lt; LTM - 1 SD) and locations with late maturity (&gt; LTM + 1 SD).\nDescribe the observed patterns and speculate about the underlying reasons. In addition, download a digital elevation map for the United States (30s resolution), and compare differences in altitude (e.g. a boxplot) across locations where you do or do not see any patterns in phenology.\n\n\n\n\n\n\n\n\nFigure 2.1: The location of the Adirondack mountains in the North-Eastern United States\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse details in REF, REF and REF to answer these questions, by considering all data products and methods mentioned. Additional meta-data will need to be consulted online to provide context or data conversion instructions in some cases. Where necessary consult the relevant scientific literature.\n\n\n\n\n2.1.3 Scaling the calculation of phenology metrics\nIn this exercise you will be required to download external data manually. First you will have to sign up for a NASA EarthData login to access the required data. The NASA EarthData login provides access to a wide range of data products.\nOnce signed in, download the data MCD13C1 product for the year 2022. The MCD13C1 product provides vegetation indices (VI), such as the Enhanced Vegetation Index (EVI) and Normalized Difference Vegetation Index (NDVI) data products on a down-sampled climate model grid (CMG, at 0.05\\(^\\circ\\) or ~5km resolution). This down-sampled data product reduces the volume of data to download and process, but should allow you to explore broad continental scale patterns when calculating vegetation (or land surface) phenology metrics.\nWith all data downloaded:\n\nCombine all EVI data (23 layers) into a single compressed geotiff file (write to file)\nRead in the geotiff file to work faster from memory\nFor a first trial crop the full dataset to 26\\(^\\circ\\)W, 20\\(^\\circ\\)E, 31\\(^\\circ\\)N, 70\\(^\\circ\\)N\nApply the algorithm as outlined in REF using a start of season greenup signal of 25% the seasonal EVI amplitude\nAssess the performance of the algorithm across the globe and discuss its consistency.\n\nWhere does it fail? How does it fail?\nWhere necessary, inspect point locations to explore potential issues.\nIf possible, address any issues by altering the original algorithm.\n\nCould you scale this globally?\n\nHow long would it take?\nCan you improve calculation times?\n\n\nPlot the global phenology maps, and its various iterations in the R markdown notebook.\n\n\n\n\n\n\nNote\n\n\n\nAll information for this exercise can be found in REF and REF. As before, additional meta-data will need to be consulted online to provide context or data conversion instructions in some cases.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "exercises.html#phenology-modelling",
    "href": "exercises.html#phenology-modelling",
    "title": "2  Exercise",
    "section": "2.2 Phenology modelling",
    "text": "2.2 Phenology modelling\n\nHow can you improve the model used to regionally scale the results in REF?\n\nProvide at least three (3) ways to improve the model used.\n\nImplement at least one of these methods\nStatistically compare the results with the MODIS MCD12Q2 phenology product\n\ncompare the data spatially\ndescribe why you might or might not see the same patterns\nconsider that 2010 was a ‘special’ year for the north east of the US",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "exercises.html#land-use-and-land-cover-modelling",
    "href": "exercises.html#land-use-and-land-cover-modelling",
    "title": "2  Exercise",
    "section": "2.3 Land-Use and Land-Cover modelling",
    "text": "2.3 Land-Use and Land-Cover modelling\n\nHow can you improve the model used to map LULC?\n\nProvide at least four (4) ways to improve the model used.\n\nImplement at least two of these methods yourself\nDemonstrate improved model skill by submitting your model results to our internal leaderboard\n\nthe leaderboard requires you to submit a CSV file with labels\n\ntraining data can be downloaded here\ntest data (out-of-sample) can be downloaded here, note that this is unlabelled\nsubmissions should be made as a pull request to the AGDS2 course repository\nyour CSV file with labels should be stored in data/leaderboard/fall_2023\nthe file should be named xyz_results.csv (replace xyz with your github username)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse the appropriate APIs to download the required data.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exercise</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Boehmke, Brad, and Brandon M Greenwell. 2020. Hands-On\nMachine Learning with R.\nBoca Raton, US: CRC Press. https://www.routledge.com/Hands-On-Machine-Learning-with-R/Boehmke-Greenwell/p/book/9781138495685.\n\n\nd’Andrimont, Raphaël, Momchil Yordanov, Laura Martinez-Sanchez, Beatrice\nEiselt, Alessandra Palmieri, Paolo Dominici, Javier Gallego, et al.\n2020. “Harmonised LUCAS in-Situ Land Cover and Use\nDatabase for Field Surveys from 2006 to 2018 in the\nEuropean Union.” Scientific\nData 7 (1): 352. https://doi.org/10.1038/s41597-020-00675-z.\n\n\nFriedl, M A, D K McIver, J C F Hodges, X Y Zhang, D Muchoney, A H\nStrahler, C E Woodcock, et al. 2002. “Global Land Cover Mapping\nfrom MODIS: Algorithms and Early Results.”\nRemote Sensing of Environment 83 (1-2): 287–302. http://www.sciencedirect.com/science/article/B6V6V-46RDDFS-2/2/498151a48b317e5bb23b15033a694d4e.\n\n\nFriedl, M A, D Sulla-Menashe, B Tan, A Schneider, N Ramankutty, A\nSibley, and X M Huang. 2010. “MODIS\nCollection 5 Global Land Cover: Algorithm\nRefinements and Characterization of New Datasets.” Remote\nSensing of Environment 114 (1): 168–82. https://doi.org/10.1016/j.rse.2009.08.016.\n\n\nFritz, Steffen, Linda See, Christoph Perger, Ian McCallum, Christian\nSchill, Dmitry Schepaschenko, Martina Duerauer, et al. 2017. “A\nGlobal Dataset of Crowdsourced Land Cover and Land Use Reference\nData.” Scientific Data 4 (1): 170075. https://doi.org/10.1038/sdata.2017.75.\n\n\nHuete, A, K Didan, T Miura, E P Rodriguez, X Gao, and L G Ferreira.\n2002. “Overview of the Radiometric and Biophysical Performance of\nthe MODIS Vegetation Indices.” Remote Sensing of\nEnvironment 83 (1-2): 195–213. citeulike-article-id:274524http://dx.doi.org/10.1016/S0034-4257(02)00096-2.\n\n\nHufkens, Koen. 2023. “Bluegreen-Labs/Appeears: Appeears: An\nInterface to the NASA AppEEARS\nAPI.” Zenodo. https://doi.org/10.5281/zenodo.7958270.\n\n\nKuhn, Max, and Julia Silge. 2022. Tidy Modeling with\nR: A Framework for\nModeling in the Tidyverse. 1st edition.\nBeijing Boston Farnham Sebastopol Tokyo: O’Reilly Media.\n\n\nZeng, Yelu, Dalei Hao, Alfredo Huete, Benjamin Dechant, Joe Berry, Jing\nM. Chen, Joanna Joiner, et al. 2022. “Optical Vegetation Indices\nfor Monitoring Terrestrial Ecosystems Globally.” Nature\nReviews Earth & Environment 3 (7): 477–93. https://doi.org/10.1038/s43017-022-00298-5.",
    "crumbs": [
      "Home",
      "References"
    ]
  },
  {
    "objectID": "appendix_setup.html",
    "href": "appendix_setup.html",
    "title": "Appendix A — Setup",
    "section": "",
    "text": "A.1 Required packages\nA common Integrated Development Environment (IDE) for R is Rstudio by Posit.co. RStudio can be downloaded for free, and provides you with an interface in which a command line terminal, a text editor, a plotting window and file manager are combined. Many other features are also included.\nYou can download and install the RStudio IDE from the posit.co website:\nhttps://posit.co/download/rstudio-desktop/\nSelect the correct download for your current operating system.\nTo run this course a set of R packages is required. The below script lets you quickly install all of them, in the correct order.\n# Windows is sensitive to the order of installation\n# of some of the packages so follow this order \n# as noted below, on other systems this might be\n# less of an issue but follow the instructions\n# regardless\n\n# First install the rlang packages which provides\n# R functionalities needed by/for other packages\n# in particular dplyr \ninstall.packages(\"rlang\")\n\n# next install dplyr needed to manipulate\n# tidy data as discussed in the R crash course\ninstall.packages(\"dplyr\")\n\n# for convenient plotting we also install\n# ggplot2 (this is not required but most plots shown\n# are generated using ggplot)\ninstall.packages(\"ggplot2\")\ninstall.packages(\"patchwork\")\ninstall.packages(\"hexbin\")\ninstall.packages(\"leaflet\")\n\n# to render markdown documents, install these packages\ninstall.packages(\"rmarkdown\", \"knitr\") \n\n# to deal with relative paths in R markdown\n# install the here package\ninstall.packages(\"here\")\n\n# next up are the installs of the geospatial\n# libraries, these can be installed in one\n# go\ninstall.packages(c(\"terra\",\"tidyterra\",\"sf\",\"MODISTools\"))\ninstall.packages(\"geodata\")\ninstall.packages(\"signal\")\n\ninstall.packages(\"phenocamr\")\ninstall.packages(\"daymetr\")\ninstall.packages(\"rsample\")\ninstall.packages(\"parsnip\")\ninstall.packages(\"workflows\")\ninstall.packages(\"tune\")\ninstall.packages(\"dials\")\ninstall.packages(\"caret\")\ninstall.packages(\"GenSA\")\ninstall.packages(\"appeears\")\ninstall.packages(\"xgboost\")",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "appendix_licensing.html",
    "href": "appendix_licensing.html",
    "title": "Appendix B — Licensing",
    "section": "",
    "text": "All rights belong to the referenced right holders. In absence of any explicit reference to right holders (in figure captions or other materials) the rights reside with the author of this manuscript under the below license.\n\n\n\n\n\n\nLicense\n\n\n\nPlease note that this work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Licensing</span>"
    ]
  },
  {
    "objectID": "appendix_config.html",
    "href": "appendix_config.html",
    "title": "Appendix C — Book configuration",
    "section": "",
    "text": "The book was rendered on github using the following package configuration:\n\nrenv::diagnostics()\n\nDiagnostics Report [renv 0.17.3]\n================================\n\n# Session Info =======================\nR version 4.5.1 (2025-06-13)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.6\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Zurich\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] htmltools_0.5.8.1 tools_4.5.1       rstudioapi_0.17.1 rmarkdown_2.30   \n [9] knitr_1.50        jsonlite_2.0.0    xfun_0.54         digest_0.6.37    \n[13] rlang_1.1.6       renv_0.17.3       evaluate_1.0.5   \n\n# Project ============================\nProject path: \"~/GitHub/fabern/drought_predictors_competition\"\n\n# Status =============================\nThe following package(s) are out of sync:\n\n   Package   Lockfile Version   Library Version\n       hms              1.1.3             1.1.4\n      lava              1.8.1             1.8.2\n   listenv              0.9.1            0.10.0\n progressr             0.16.0            0.17.0\n  timeDate           4041.110          4051.111\n      tune              2.0.0             2.0.1\n      xfun               0.53              0.54\n      xml2              1.4.0             1.4.1\n\nUse `renv::snapshot()` to save the state of your library to the lockfile.\nUse `renv::restore()` to restore your library from the lockfile.\n\n\n# Packages ===========================\n                     Library Source   Lockfile Source Path Dependency\nCFtime                 1.7.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nDBI                    1.2.3   CRAN      1.2.3   CRAN  [1]   indirect\nDiceDesign              1.10   CRAN       1.10   CRAN  [1]   indirect\nGPfit                  1.0-9   CRAN      1.0-9   CRAN  [1]   indirect\nGenSA               1.1.14.1   CRAN   1.1.14.1   CRAN  [1]       &lt;NA&gt;\nKernSmooth           2.23-26   CRAN    2.23-26   CRAN  [2]   indirect\nMASS                  7.3-65   CRAN     7.3-65   CRAN  [2]   indirect\nMODISTools             1.1.5   CRAN      1.1.5   CRAN  [1]     direct\nMatrix                 1.7-3   CRAN      1.7-3   CRAN  [2]   indirect\nModelMetrics         1.2.2.2   CRAN    1.2.2.2   CRAN  [1]       &lt;NA&gt;\nR6                     2.6.1   CRAN      2.6.1   CRAN  [1]   indirect\nRColorBrewer           1.1-3   CRAN      1.1-3   CRAN  [1]   indirect\nRNetCDF               2.11-1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nRcpp                   1.1.0   CRAN      1.1.0   CRAN  [1]   indirect\nS7                     0.2.0   CRAN      0.2.0   CRAN  [1]   indirect\nSQUAREM               2021.1   CRAN     2021.1   CRAN  [1]   indirect\nV8                     8.0.1   CRAN      8.0.1   CRAN  [1]   indirect\nappeears                 1.1   CRAN        1.1   CRAN  [1]     direct\naskpass                1.2.1   CRAN      1.2.1   CRAN  [1]   indirect\nbackports              1.5.0   CRAN      1.5.0   CRAN  [1]   indirect\nbase64enc              0.1-3   CRAN      0.1-3   CRAN  [1]   indirect\nbit                    4.6.0   CRAN      4.6.0   CRAN  [1]   indirect\nbit64                4.6.0-1   CRAN    4.6.0-1   CRAN  [1]   indirect\nblob                   1.2.4   CRAN      1.2.4   CRAN  [1]   indirect\nboot                  1.3-31   CRAN       &lt;NA&gt;   &lt;NA&gt;  [2]       &lt;NA&gt;\nbrew                  1.0-10   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nbrio                   1.1.5   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nbroom                 1.0.10   CRAN     1.0.10   CRAN  [1]   indirect\nbslib                  0.9.0   CRAN      0.9.0   CRAN  [1]   indirect\nbundle                 0.1.2   CRAN      0.1.2   CRAN  [1]       &lt;NA&gt;\ncachem                 1.1.0   CRAN      1.1.0   CRAN  [1]   indirect\ncallr                  3.7.6   CRAN      3.7.6   CRAN  [1]   indirect\ncaret                  7.0-1   CRAN      7.0-1   CRAN  [1]       &lt;NA&gt;\ncellranger             1.1.0   CRAN      1.1.0   CRAN  [1]   indirect\nclass                 7.3-23   CRAN     7.3-23   CRAN  [2]   indirect\nclassInt              0.4-11   CRAN     0.4-11   CRAN  [1]   indirect\ncli                    3.6.5   CRAN      3.6.5   CRAN  [1]   indirect\nclipr                  0.8.0   CRAN      0.8.0   CRAN  [1]   indirect\nclock                  0.7.3   CRAN      0.7.3   CRAN  [1]   indirect\ncluster              2.1.8.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [2]       &lt;NA&gt;\ncodetools             0.2-20   CRAN     0.2-20   CRAN  [2]   indirect\ncommonmark             2.0.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ncompiler                &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nconflicted             1.2.0   CRAN      1.2.0   CRAN  [1]   indirect\ncowplot                1.2.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ncpp11                  0.5.2   CRAN      0.5.2   CRAN  [1]   indirect\ncrayon                 1.5.3   CRAN      1.5.3   CRAN  [1]   indirect\ncredentials            2.0.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ncrosstalk              1.2.2   CRAN      1.2.2   CRAN  [1]   indirect\ncrul                   1.6.0   CRAN      1.6.0   CRAN  [1]   indirect\ncurl                   7.0.0   CRAN      7.0.0   CRAN  [1]   indirect\ndata.table            1.17.8   CRAN     1.17.8   CRAN  [1]   indirect\ndaymetr                1.7.1   CRAN      1.7.1   CRAN  [1]     direct\ndbplyr                 2.5.1   CRAN      2.5.1   CRAN  [1]   indirect\ndesc                   1.4.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ndevtools               2.4.6   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ndiagram                1.6.5   CRAN      1.6.5   CRAN  [1]   indirect\ndials                  1.4.2   CRAN      1.4.2   CRAN  [1]     direct\ndiffobj                0.3.6   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ndigest                0.6.37   CRAN     0.6.37   CRAN  [1]   indirect\ndownlit                0.4.4   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ndplyr                  1.1.4   CRAN      1.1.4   CRAN  [1]     direct\ndtplyr                 1.3.2   CRAN      1.3.2   CRAN  [1]   indirect\ne1071                 1.7-16   CRAN     1.7-16   CRAN  [1]   indirect\nellipsis               0.3.2   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nevaluate               1.0.5   CRAN      1.0.5   CRAN  [1]   indirect\nfansi                  1.0.6   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nfarver                 2.1.2   CRAN      2.1.2   CRAN  [1]   indirect\nfastmap                1.2.0   CRAN      1.2.0   CRAN  [1]   indirect\nfilelock               1.0.3   CRAN      1.0.3   CRAN  [1]   indirect\nfontawesome            0.5.3   CRAN      0.5.3   CRAN  [1]   indirect\nforcats                1.0.1   CRAN      1.0.1   CRAN  [1]   indirect\nforeach                1.5.2   CRAN      1.5.2   CRAN  [1]       &lt;NA&gt;\nforeign               0.8-90   CRAN       &lt;NA&gt;   &lt;NA&gt;  [2]       &lt;NA&gt;\nfs                     1.6.6   CRAN      1.6.6   CRAN  [1]   indirect\nfurrr                  0.3.1   CRAN      0.3.1   CRAN  [1]   indirect\nfuture                1.67.0   CRAN     1.67.0   CRAN  [1]   indirect\nfuture.apply          1.20.0   CRAN     1.20.0   CRAN  [1]   indirect\ngargle                 1.6.0   CRAN      1.6.0   CRAN  [1]   indirect\ngenerics               0.1.4   CRAN      0.1.4   CRAN  [1]   indirect\ngeodata                0.6-6   CRAN      0.6-6   CRAN  [1]     direct\ngeojson                0.3.5   CRAN      0.3.5   CRAN  [1]   indirect\ngeojsonio             0.11.3   CRAN     0.11.3   CRAN  [1]   indirect\ngeojsonsf              2.0.3   CRAN      2.0.3   CRAN  [1]   indirect\ngeometries             0.2.4   CRAN      0.2.4   CRAN  [1]   indirect\ngert                   2.1.5   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ngetPass                0.2-4   CRAN      0.2-4   CRAN  [1]   indirect\nggplot2                4.0.0   CRAN      4.0.0   CRAN  [1]     direct\nggthemes               5.1.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ngh                     1.5.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ngitcreds               0.1.2   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nglobals               0.18.0   CRAN     0.18.0   CRAN  [1]   indirect\nglue                   1.8.0   CRAN      1.8.0   CRAN  [1]   indirect\ngoogledrive            2.1.2   CRAN      2.1.2   CRAN  [1]   indirect\ngooglesheets4          1.1.2   CRAN      1.1.2   CRAN  [1]   indirect\ngower                  1.0.2   CRAN      1.0.2   CRAN  [1]   indirect\ngrDevices               &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\ngraphics                &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\ngrid                    &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\ngridExtra                2.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ngtable                 0.3.6   CRAN      0.3.6   CRAN  [1]   indirect\nhardhat                1.4.2   CRAN      1.4.2   CRAN  [1]   indirect\nhaven                  2.5.5   CRAN      2.5.5   CRAN  [1]   indirect\nhere                   1.0.2   CRAN      1.0.2   CRAN  [1]     direct\nhexbin                1.28.5   CRAN     1.28.5   CRAN  [1]       &lt;NA&gt;\nhighr                   0.11   CRAN       0.11   CRAN  [1]   indirect\nhms                    1.1.4   RSPM      1.1.3   CRAN  [1]   indirect\nhtmltools            0.5.8.1   CRAN    0.5.8.1   CRAN  [1]   indirect\nhtmlwidgets            1.6.4   CRAN      1.6.4   CRAN  [1]   indirect\nhttpcode               0.3.0   CRAN      0.3.0   CRAN  [1]   indirect\nhttpuv                1.6.16   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nhttr                   1.4.7   CRAN      1.4.7   CRAN  [1]   indirect\nhttr2                  1.2.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nids                    1.0.1   CRAN      1.0.1   CRAN  [1]   indirect\ninfer                  1.0.9   CRAN      1.0.9   CRAN  [1]   indirect\nini                    0.3.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nipred                 0.9-15   CRAN     0.9-15   CRAN  [1]   indirect\nisoband                0.2.7   CRAN      0.2.7   CRAN  [1]   indirect\niterators             1.0.14   CRAN     1.0.14   CRAN  [1]       &lt;NA&gt;\njqr                    1.4.0   CRAN      1.4.0   CRAN  [1]   indirect\njquerylib              0.1.4   CRAN      0.1.4   CRAN  [1]   indirect\njsonify                1.2.2   CRAN      1.2.2   CRAN  [1]   indirect\njsonlite               2.0.0   CRAN      2.0.0   CRAN  [1]   indirect\nkeyring                1.4.1   CRAN      1.4.1   CRAN  [1]   indirect\nkhroma                1.17.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nknitr                   1.50   CRAN       1.50   CRAN  [1]   indirect\nlabeling               0.4.3   CRAN      0.4.3   CRAN  [1]   indirect\nlater                  1.4.4   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nlattice               0.22-7   CRAN     0.22-7   CRAN  [2]   indirect\nlava                   1.8.2   CRAN      1.8.1   CRAN  [1]   indirect\nlazyeval               0.2.2   CRAN      0.2.2   CRAN  [1]   indirect\nleaflet                2.2.3   CRAN      2.2.3   CRAN  [1]     direct\nleaflet.providers      2.0.0   CRAN      2.0.0   CRAN  [1]   indirect\nlhs                    1.2.0   CRAN      1.2.0   CRAN  [1]   indirect\nlifecycle              1.0.4   CRAN      1.0.4   CRAN  [1]   indirect\nlistenv               0.10.0   CRAN      0.9.1   CRAN  [1]   indirect\nlubridate              1.9.4   CRAN      1.9.4   CRAN  [1]   indirect\nmagrittr               2.0.4   CRAN      2.0.4   CRAN  [1]   indirect\nmemoise                2.0.1   CRAN      2.0.1   CRAN  [1]   indirect\nmethods                 &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nmgcv                   1.9-3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [2]       &lt;NA&gt;\nmime                    0.13   CRAN       0.13   CRAN  [1]   indirect\nminiUI                 0.1.2   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nmodeldata              1.5.1   CRAN      1.5.1   CRAN  [1]   indirect\nmodelenv               0.2.0   CRAN      0.2.0   CRAN  [1]   indirect\nmodelr                0.1.11   CRAN     0.1.11   CRAN  [1]   indirect\nncdf4                   1.24   CRAN       1.24   CRAN  [1]   indirect\nncmeta                 0.4.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nnlme                 3.1-168   CRAN    3.1-168   CRAN  [2]       &lt;NA&gt;\nnnet                  7.3-20   CRAN     7.3-20   CRAN  [2]   indirect\nnumDeriv          2016.8-1.1   CRAN 2016.8-1.1   CRAN  [1]   indirect\nopenssl                2.3.4   CRAN      2.3.4   CRAN  [1]   indirect\notel                   0.2.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\npROC                1.19.0.1   CRAN   1.19.0.1   CRAN  [1]       &lt;NA&gt;\nparallel                &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nparallelly            1.45.1   CRAN     1.45.1   CRAN  [1]   indirect\nparsnip                1.3.3   CRAN      1.3.3   CRAN  [1]     direct\npatchwork              1.3.2   CRAN      1.3.2   CRAN  [1]     direct\npillar                1.11.1   CRAN     1.11.1   CRAN  [1]   indirect\npkgbuild               1.4.8   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\npkgconfig              2.0.3   CRAN      2.0.3   CRAN  [1]   indirect\npkgdown                2.2.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\npkgload                1.4.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nplyr                   1.8.9   CRAN      1.8.9   CRAN  [1]       &lt;NA&gt;\npng                    0.1-8   CRAN      0.1-8   CRAN  [1]   indirect\npraise                 1.0.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nprettyunits            1.2.0   CRAN      1.2.0   CRAN  [1]   indirect\nprocessx               3.8.6   CRAN      3.8.6   CRAN  [1]   indirect\nprodlim           2025.04.28   CRAN 2025.04.28   CRAN  [1]   indirect\nprofvis                0.4.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nprogress               1.2.3   CRAN      1.2.3   CRAN  [1]   indirect\nprogressr             0.17.0   CRAN     0.16.0   CRAN  [1]   indirect\npromises               1.5.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nprotolite              2.3.1   CRAN      2.3.1   CRAN  [1]   indirect\nproxy                 0.4-27   CRAN     0.4-27   CRAN  [1]   indirect\nps                     1.9.1   CRAN      1.9.1   CRAN  [1]   indirect\npurrr                  1.1.0   CRAN      1.1.0   CRAN  [1]   indirect\nragg                   1.5.0   CRAN      1.5.0   CRAN  [1]   indirect\nrapidjsonr             1.2.0   CRAN      1.2.0   CRAN  [1]   indirect\nrappdirs               0.3.3   CRAN      0.3.3   CRAN  [1]   indirect\nraster                3.6-32   CRAN     3.6-32   CRAN  [1]   indirect\nrcmdcheck              1.4.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nreadr                  2.1.5   CRAN      2.1.5   CRAN  [1]     direct\nreadxl                 1.4.5   CRAN      1.4.5   CRAN  [1]   indirect\nrecipes                1.3.1   CRAN      1.3.1   CRAN  [1]   indirect\nrematch                2.0.0   CRAN      2.0.0   CRAN  [1]   indirect\nrematch2               2.1.2   CRAN      2.1.2   CRAN  [1]   indirect\nremotes                2.5.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nrenv                  0.17.3   CRAN     0.17.3   CRAN  [1]     direct\nreprex                 2.1.1   CRAN      2.1.1   CRAN  [1]   indirect\nreshape2               1.4.4   CRAN      1.4.4   CRAN  [1]       &lt;NA&gt;\nrgeco                    0.9 GitHub       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nrlang                  1.1.6   CRAN      1.1.6   CRAN  [1]   indirect\nrmarkdown               2.30   CRAN       2.30   CRAN  [1]     direct\nrnaturalearth          1.1.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nrnaturalearthdata      1.0.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nroxygen2               7.3.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nrpart                 4.1.24   CRAN     4.1.24   CRAN  [2]   indirect\nrprojroot              2.1.1   CRAN      2.1.1   CRAN  [1]   indirect\nrsample                1.3.1   CRAN      1.3.1   CRAN  [1]     direct\nrstudioapi            0.17.1   CRAN     0.17.1   CRAN  [1]   indirect\nrversions              3.0.0   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nrvest                  1.0.5   CRAN      1.0.5   CRAN  [1]   indirect\ns2                     1.1.9   CRAN      1.1.9   CRAN  [1]   indirect\nsass                  0.4.10   CRAN     0.4.10   CRAN  [1]   indirect\nscales                 1.4.0   CRAN      1.4.0   CRAN  [1]   indirect\nscico             1.5.0.9000 GitHub       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nselectr                0.4-2   CRAN      0.4-2   CRAN  [1]   indirect\nsessioninfo            1.2.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nsf                    1.0-21   CRAN     1.0-21   CRAN  [1]   indirect\nsfd                    0.1.0   CRAN      0.1.0   CRAN  [1]   indirect\nsfheaders              0.4.4   CRAN      0.4.4   CRAN  [1]   indirect\nshape                1.4.6.1   CRAN    1.4.6.1   CRAN  [1]   indirect\nshiny                 1.11.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nsignal                 1.8-1   CRAN      1.8-1   CRAN  [1]       &lt;NA&gt;\nslider                 0.3.2   CRAN      0.3.2   CRAN  [1]   indirect\nsourcetools          0.1.7-1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nsp                     2.2-0   CRAN      2.2-0   CRAN  [1]   indirect\nsparsevctrs            0.3.4   CRAN      0.3.4   CRAN  [1]   indirect\nspatial               7.3-18   CRAN       &lt;NA&gt;   &lt;NA&gt;  [2]       &lt;NA&gt;\nsplines                 &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nstats                   &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nstringi                1.8.7   CRAN      1.8.7   CRAN  [1]   indirect\nstringr                1.5.2   CRAN      1.5.2   CRAN  [1]   indirect\nsurvival               3.8-3   CRAN      3.8-3   CRAN  [2]   indirect\nsys                    3.4.3   CRAN      3.4.3   CRAN  [1]   indirect\nsystemfonts            1.3.1   CRAN      1.3.1   CRAN  [1]   indirect\ntailor                 0.1.0   CRAN      0.1.0   CRAN  [1]   indirect\nterra                 1.8-70   CRAN     1.8-70   CRAN  [1]     direct\ntestthat               3.2.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\ntextshaping            1.0.4   CRAN      1.0.4   CRAN  [1]   indirect\ntibble                 3.3.0   CRAN      3.3.0   CRAN  [1]   indirect\ntidymodels             1.4.1   CRAN      1.4.1   CRAN  [1]     direct\ntidyr                  1.3.1   CRAN      1.3.1   CRAN  [1]     direct\ntidyselect             1.2.1   CRAN      1.2.1   CRAN  [1]   indirect\ntidyterra              0.7.2   CRAN      0.7.2   CRAN  [1]       &lt;NA&gt;\ntidyverse              2.0.0   CRAN      2.0.0   CRAN  [1]     direct\ntimeDate            4051.111   CRAN   4041.110   CRAN  [1]   indirect\ntimechange             0.3.0   CRAN      0.3.0   CRAN  [1]   indirect\ntinytex                 0.57   CRAN       0.57   CRAN  [1]   indirect\ntools                   &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\ntriebeard              0.4.1   CRAN      0.4.1   CRAN  [1]   indirect\ntune                   2.0.1   CRAN      2.0.0   CRAN  [1]     direct\ntzdb                   0.5.0   CRAN      0.5.0   CRAN  [1]   indirect\nunits                  1.0-0   CRAN      1.0-0   CRAN  [1]   indirect\nurlchecker             1.0.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nurltools             1.7.3.1   CRAN    1.7.3.1   CRAN  [1]   indirect\nusethis                3.2.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nutf8                   1.2.6   CRAN      1.2.6   CRAN  [1]   indirect\nutils                   &lt;NA&gt;   &lt;NA&gt;       &lt;NA&gt;   &lt;NA&gt;  [2]   indirect\nuuid                   1.2-1   CRAN      1.2-1   CRAN  [1]   indirect\nvctrs                  0.6.5   CRAN      0.6.5   CRAN  [1]   indirect\nviridis                0.6.5   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nviridisLite            0.4.2   CRAN      0.4.2   CRAN  [1]   indirect\nvroom                  1.6.6   CRAN      1.6.6   CRAN  [1]     direct\nwaldo                  0.6.2   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nwarp                   0.2.1   CRAN      0.2.1   CRAN  [1]   indirect\nwhisker                0.4.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nwithr                  3.0.2   CRAN      3.0.2   CRAN  [1]   indirect\nwk                     0.9.4   CRAN      0.9.4   CRAN  [1]   indirect\nworkflows              1.3.0   CRAN      1.3.0   CRAN  [1]     direct\nworkflowsets           1.1.1   CRAN      1.1.1   CRAN  [1]   indirect\nxfun                    0.54   RSPM       0.53   CRAN  [1]   indirect\nxgboost             1.7.11.1   CRAN   1.7.11.1   CRAN  [1]       &lt;NA&gt;\nxml2                   1.4.1   CRAN      1.4.0   CRAN  [1]   indirect\nxopen                  1.0.1   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nxtable                 1.8-4   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\nyaml                  2.3.10   CRAN     2.3.10   CRAN  [1]   indirect\nyardstick              1.3.2   CRAN      1.3.2   CRAN  [1]   indirect\nzip                    2.3.3   CRAN       &lt;NA&gt;   &lt;NA&gt;  [1]       &lt;NA&gt;\n\n[1]: /Users/faber/GitHub/fabern/drought_predictors_competition/renv/library/R-4.5/aarch64-apple-darwin20\n[2]: /Users/faber/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.5/aarch64-apple-darwin20/4cd76b74   \n\n# ABI ================================\n* No ABI conflicts were detected in the set of installed packages.\n\n# User Profile =======================\n[no user profile detected]\n\n# Settings ===========================\nList of 11\n $ bioconductor.version     : chr(0) \n $ external.libraries       : chr(0) \n $ ignored.packages         : chr(0) \n $ package.dependency.fields: chr [1:3] \"Imports\" \"Depends\" \"LinkingTo\"\n $ r.version                : chr(0) \n $ snapshot.type            : chr \"implicit\"\n $ use.cache                : logi TRUE\n $ vcs.ignore.cellar        : logi TRUE\n $ vcs.ignore.library       : logi TRUE\n $ vcs.ignore.local         : logi TRUE\n $ vcs.manage.ignores       : logi TRUE\n\n# Options ============================\nList of 9\n $ defaultPackages                     : chr [1:6] \"datasets\" \"utils\" \"grDevices\" \"graphics\" ...\n $ download.file.method                : NULL\n $ download.file.extra                 : NULL\n $ install.packages.compile.from.source: chr \"interactive\"\n $ pkgType                             : chr \"both\"\n $ repos                               : Named chr \"https://cloud.r-project.org\"\n  ..- attr(*, \"names\")= chr \"CRAN\"\n $ renv.consent                        : logi TRUE\n $ renv.project.path                   : chr \"/Users/faber/GitHub/fabern/drought_predictors_competition\"\n $ renv.verbose                        : logi TRUE\n\n# Environment Variables ==============\nHOME                        = /Users/faber\nLANG                        = en_US.UTF-8\nMAKE                        = make\nR_LIBS                      = &lt;NA&gt;\nR_LIBS_SITE                 = /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/site-library\nR_LIBS_USER                 = /Users/faber/GitHub/fabern/drought_predictors_competition/renv/library/R-4.5/aarch64-apple-darwin20:/Users/faber/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.5/aarch64-apple-darwin20/4cd76b74\nRENV_DEFAULT_R_ENVIRON      = &lt;NA&gt;\nRENV_DEFAULT_R_ENVIRON_USER = &lt;NA&gt;\nRENV_DEFAULT_R_LIBS         = &lt;NA&gt;\nRENV_DEFAULT_R_LIBS_SITE    = /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/site-library\nRENV_DEFAULT_R_LIBS_USER    = /Users/faber/Library/R/arm64/4.5/library\nRENV_DEFAULT_R_PROFILE      = &lt;NA&gt;\nRENV_DEFAULT_R_PROFILE_USER = &lt;NA&gt;\nRENV_PROJECT                = /Users/faber/GitHub/fabern/drought_predictors_competition\n\n# PATH ===============================\n- /Users/faber/.local/bin\n- /Users/faber/.juliaup/bin\n- /usr/local/bin\n- /usr/local/bin\n- /usr/local/anaconda3/condabin\n- /usr/local/opt/openssl/bin\n- /usr/local/bin\n- /System/Cryptexes/App/usr/bin\n- /usr/bin\n- /bin\n- /usr/sbin\n- /sbin\n- /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin\n- /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin\n- /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin\n- /opt/homebrew/bin\n- /opt/homebrew/sbin\n- /Applications/quarto/bin\n- /Library/TeX/texbin\n- /usr/texbin\n- /Applications/RStudio.app/Contents/Resources/app/quarto/bin\n- /Applications/RStudio.app/Contents/Resources/app/bin/postback\n\n# Cache ==============================\nThere are a total of 264 packages installed in the renv cache.\nCache path: \"~/Library/Caches/org.R-project.R/R/renv/cache/v5/R-4.5/aarch64-apple-darwin20\"",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Book configuration</span>"
    ]
  }
]